{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "\n",
    "DATASET_OPTIONS = [\"steel\", \"fetal_health\"]\n",
    "DATASET = \"fetal_health\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == \"steel\":\n",
    "    if not os.path.exists('data/steel'):\n",
    "        os.makedirs('data/steel')\n",
    "    if not os.path.exists('data/steel/steel.train'):\n",
    "        # fetch dataset\n",
    "        steel_plates_faults = fetch_ucirepo(id=198)\n",
    "\n",
    "        # data (as pandas dataframes)\n",
    "        X = steel_plates_faults.data.features\n",
    "        y = steel_plates_faults.data.targets\n",
    "\n",
    "        # preprocess the targets\n",
    "        # put the class as the index of the 1 in the row\n",
    "        y = y.idxmax(axis=1)\n",
    "\n",
    "        # convert to numbers\n",
    "        y = y.astype('category').cat.codes\n",
    "\n",
    "        # split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "        # saving the data\n",
    "        X_train.to_csv('data/steel/steel.train', index=False)\n",
    "        X_test.to_csv('data/steel/steel.test', index=False)\n",
    "        y_train.to_csv('data/steel/steel.train.target', index=False)\n",
    "        y_test.to_csv('data/steel/steel.test.target', index=False)\n",
    "\n",
    "        print('Data saved in data/steel/steel.train, data/steel/steel.test, data/steel/steel.train.target, data/steel/steel.test.target')\n",
    "    else:\n",
    "        print('Data already exists in data/steel/steel.train, data/steel/steel.test, data/steel/steel.train.target, data/steel/steel.test.target')\n",
    "\n",
    "    # load the data\n",
    "    X_train = pd.read_csv('data/steel/steel.train')\n",
    "    X_test = pd.read_csv('data/steel/steel.test')\n",
    "    y_train = pd.read_csv('data/steel/steel.train.target')\n",
    "    y_test = pd.read_csv('data/steel/steel.test.target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exists in data/fetal_health/fetal_health.train, data/fetal_health/fetal_health.test, data/fetal_health/fetal_health.train.target, data/fetal_health/fetal_health.test.target\n"
     ]
    }
   ],
   "source": [
    "if DATASET == \"fetal_health\":\n",
    "    if not os.path.exists('data/fetal_health'):\n",
    "        os.makedirs('data/fetal_health')\n",
    "\n",
    "    if not os.path.exists('data/fetal_health/fetal_health.train'):\n",
    "        # this data is meant to have been downloaded from kaggle\n",
    "        fetal_health = pd.read_csv('data/fetal_health/fetal_health.csv')\n",
    "\n",
    "        # split data\n",
    "        X = fetal_health.drop(columns='fetal_health')\n",
    "        y = fetal_health['fetal_health']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "        # saving the data\n",
    "        X_train.to_csv('data/fetal_health/fetal_health.train', index=False)\n",
    "        X_test.to_csv('data/fetal_health/fetal_health.test', index=False)\n",
    "        y_train.to_csv('data/fetal_health/fetal_health.train.target', index=False)\n",
    "        y_test.to_csv('data/fetal_health/fetal_health.test.target', index=False)\n",
    "\n",
    "        print('Data saved in data/fetal_health/fetal_health.train, data/fetal_health/fetal_health.test, data/fetal_health/fetal_health.train.target, data/fetal_health/fetal_health.test.target')\n",
    "    else:\n",
    "        print('Data already exists in data/fetal_health/fetal_health.train, data/fetal_health/fetal_health.test, data/fetal_health/fetal_health.train.target, data/fetal_health/fetal_health.test.target')\n",
    "\n",
    "    # load the data\n",
    "    X_train = pd.read_csv('data/fetal_health/fetal_health.train')\n",
    "    X_test = pd.read_csv('data/fetal_health/fetal_health.test')\n",
    "    y_train = pd.read_csv('data/fetal_health/fetal_health.train.target')\n",
    "    y_test = pd.read_csv('data/fetal_health/fetal_health.test.target')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset: fetal_health\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using dataset: {DATASET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy arrays\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "def normalize(X):\n",
    "    return (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n",
    "\n",
    "# creating the tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.int64)\n",
    "y_test = torch.tensor(y_test, dtype=torch.int64)\n",
    "\n",
    "# create the dataset\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {DEVICE} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_size)\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "INPUT_SIZE = X_train.shape[1]\n",
    "OUTPUT_SIZE = y_train.max() + 1\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000 Train loss: 0.7712 Test loss: 0.8309\n",
      "Epoch 200/1000 Train loss: 0.7655 Test loss: 0.8363\n",
      "Epoch 300/1000 Train loss: 0.7642 Test loss: 0.8283\n",
      "Epoch 400/1000 Train loss: 0.7637 Test loss: 0.8332\n",
      "Epoch 500/1000 Train loss: 0.7637 Test loss: 0.8290\n",
      "Epoch 600/1000 Train loss: 0.7636 Test loss: 0.8327\n",
      "Epoch 700/1000 Train loss: 0.7643 Test loss: 0.8361\n",
      "Epoch 800/1000 Train loss: 0.7631 Test loss: 0.8353\n",
      "Epoch 900/1000 Train loss: 0.7619 Test loss: 0.8411\n",
      "Epoch 1000/1000 Train loss: 0.7654 Test loss: 0.8388\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "model = MLP(INPUT_SIZE, OUTPUT_SIZE).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            train_loss = criterion(model(X_train), y_train)\n",
    "            test_loss = criterion(model(X_test), y_test)\n",
    "            print(f'Epoch {epoch}/{EPOCHS} Train loss: {train_loss:.4f} Test loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.94      0.95       340\n",
      "           2       0.64      0.81      0.72        53\n",
      "           3       0.79      0.70      0.74        33\n",
      "\n",
      "    accuracy                           0.90       426\n",
      "   macro avg       0.80      0.82      0.80       426\n",
      "weighted avg       0.91      0.90      0.91       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test).argmax(dim=1).cpu().numpy()\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.3380\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.35      0.48       340\n",
      "           2       0.12      0.32      0.17        53\n",
      "           3       0.06      0.24      0.10        33\n",
      "\n",
      "    accuracy                           0.34       426\n",
      "   macro avg       0.32      0.30      0.25       426\n",
      "weighted avg       0.64      0.34      0.42       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# baseline dummy model\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"uniform\")\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred = dummy.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Baseline accuracy: {accuracy:.4f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 0.8920\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.94      0.95       340\n",
      "           2       0.61      0.64      0.62        53\n",
      "           3       0.73      0.82      0.77        33\n",
      "\n",
      "    accuracy                           0.89       426\n",
      "   macro avg       0.76      0.80      0.78       426\n",
      "weighted avg       0.90      0.89      0.89       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# baseline logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Logistic regression accuracy: {accuracy:.4f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
